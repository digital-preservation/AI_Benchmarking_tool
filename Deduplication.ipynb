{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an essential part of the data preprocessing\n",
    "* de-duplication\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import spacy\n",
    "import nltk\n",
    "\n",
    "import logging\n",
    "from gensim.summarization import summarize\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_a = 'H:/AI_for_Selection/a/'\n",
    "folder_path_websites = 'H:/AI_for_Selection/Websites/'\n",
    "metadata_reduced_file = 'H:/AI_for_Selection/metadata_with_filesize_lastmodified.csv'\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\svenkata\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "metadata_reduced_df = pd.read_csv(metadata_reduced_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'fileextension', 'disposal_schedule', 'repository',\n",
       "       'datelastmodified', 'parent11', 'parent10', 'parent9', 'parent8',\n",
       "       'parent7', 'parent6', 'parent5', 'parent4', 'parent3', 'parent2',\n",
       "       'parent1', 'originalname', 'documentname', 'trim_11', 'trim_10',\n",
       "       'trim_9', 'trim_8', 'trim_7', 'trim_6', 'trim_5', 'trim_4', 'trim_3',\n",
       "       'trim_2', 'trim_1', 'ret_schedule', 'selected', 'file_path',\n",
       "       'file_size', 'last_modified'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_reduced_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First remove unwanted files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_file_list = ['pdf','rtf','txt','msg','doc','docx','xls','xlsx','mbx']\n",
    "for subdir, dirnames, files  in os.walk(folder_path):\n",
    "    \n",
    "    for filename in files:\n",
    "        \n",
    "        extension = filename.split('.')[-1]\n",
    "        \n",
    "        try:\n",
    "            if (extension in accepted_file_list):\n",
    "                file = subdir+os.sep+filename\n",
    "                text = remove_nonascii(file)\n",
    "                print(summarize(text,word_count=20))\n",
    "        except:\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def remove_nonascii(file,):\n",
    "    # read files. Ignore non ascii characters\n",
    "    f = open(file,'r', encoding='latin-1')\n",
    "    text = f.read()\n",
    "    return text.encode(\"ascii\", errors=\"ignore\").decode()\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import sys\n",
    "#import os\n",
    "import hashlib\n",
    "\n",
    "def chunk_reader(fobj, chunk_size=1024):\n",
    "    \"\"\"Generator that reads a file in chunks of bytes\"\"\"\n",
    "    while True:\n",
    "        chunk = fobj.read(chunk_size)\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk\n",
    "\n",
    "def check_for_duplicates(paths, hash=hashlib.sha1):\n",
    "    hashes = {}\n",
    "    for path in paths:\n",
    "        for dirpath, dirnames, filenames in os.walk(path):\n",
    "            for filename in filenames:\n",
    "                full_path = os.path.join(dirpath, filename)\n",
    "                hashobj = hash()\n",
    "                for chunk in chunk_reader(open(full_path, 'rb')):\n",
    "                    hashobj.update(chunk)\n",
    "                file_id = (hashobj.digest(), os.path.getsize(full_path))\n",
    "                duplicate = hashes.get(file_id, None)\n",
    "                if duplicate:\n",
    "                    print \"Duplicate found: %s and %s\" % (full_path, duplicate)\n",
    "                else:\n",
    "                    hashes[file_id] = full_path\n",
    "\n",
    "if sys.argv[1:]:\n",
    "    check_for_duplicates(sys.argv[1:])\n",
    "else:\n",
    "    print \"Please pass the paths to check as parameters to the script\"'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
